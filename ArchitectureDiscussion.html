<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_iaqg1toqrhdi-3{list-style-type:none}ul.lst-kix_iaqg1toqrhdi-4{list-style-type:none}ul.lst-kix_iaqg1toqrhdi-5{list-style-type:none}.lst-kix_w9h3dmhbegf2-8>li:before{content:"\0025a0   "}ul.lst-kix_iaqg1toqrhdi-6{list-style-type:none}ul.lst-kix_iaqg1toqrhdi-7{list-style-type:none}ul.lst-kix_iaqg1toqrhdi-8{list-style-type:none}.lst-kix_w9h3dmhbegf2-7>li:before{content:"\0025cb   "}.lst-kix_fvnzs32irw6t-8>li:before{content:"\0025a0   "}.lst-kix_fvnzs32irw6t-6>li:before{content:"\0025cf   "}.lst-kix_fvnzs32irw6t-7>li:before{content:"\0025cb   "}.lst-kix_w9h3dmhbegf2-1>li:before{content:"\0025cb   "}.lst-kix_w9h3dmhbegf2-2>li:before{content:"\0025a0   "}.lst-kix_w9h3dmhbegf2-3>li:before{content:"\0025cf   "}ul.lst-kix_w9h3dmhbegf2-0{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-1{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-2{list-style-type:none}.lst-kix_w9h3dmhbegf2-4>li:before{content:"\0025cb   "}.lst-kix_w9h3dmhbegf2-6>li:before{content:"\0025cf   "}ul.lst-kix_iaqg1toqrhdi-0{list-style-type:none}ul.lst-kix_iaqg1toqrhdi-1{list-style-type:none}.lst-kix_w9h3dmhbegf2-5>li:before{content:"\0025a0   "}ul.lst-kix_iaqg1toqrhdi-2{list-style-type:none}.lst-kix_26ltftm3v6k8-0>li:before{content:"\0025cf   "}.lst-kix_fvnzs32irw6t-0>li:before{content:"\0025cf   "}.lst-kix_fvnzs32irw6t-4>li:before{content:"\0025cb   "}.lst-kix_fvnzs32irw6t-1>li:before{content:"\0025cb   "}.lst-kix_fvnzs32irw6t-5>li:before{content:"\0025a0   "}.lst-kix_fvnzs32irw6t-2>li:before{content:"\0025a0   "}.lst-kix_fvnzs32irw6t-3>li:before{content:"\0025cf   "}ul.lst-kix_26ltftm3v6k8-5{list-style-type:none}ul.lst-kix_26ltftm3v6k8-4{list-style-type:none}ul.lst-kix_26ltftm3v6k8-7{list-style-type:none}.lst-kix_iaqg1toqrhdi-8>li:before{content:"\0025a0   "}ul.lst-kix_26ltftm3v6k8-6{list-style-type:none}ul.lst-kix_26ltftm3v6k8-8{list-style-type:none}.lst-kix_qhi6vxoyigf9-0>li:before{content:"\0025cf   "}.lst-kix_iaqg1toqrhdi-7>li:before{content:"\0025cb   "}.lst-kix_qhi6vxoyigf9-1>li:before{content:"\0025cb   "}.lst-kix_qhi6vxoyigf9-3>li:before{content:"\0025cf   "}.lst-kix_qhi6vxoyigf9-2>li:before{content:"\0025a0   "}.lst-kix_iaqg1toqrhdi-1>li:before{content:"\0025cb   "}ul.lst-kix_fvnzs32irw6t-7{list-style-type:none}ul.lst-kix_fvnzs32irw6t-8{list-style-type:none}.lst-kix_iaqg1toqrhdi-0>li:before{content:"\0025cf   "}ul.lst-kix_fvnzs32irw6t-5{list-style-type:none}ul.lst-kix_fvnzs32irw6t-6{list-style-type:none}ul.lst-kix_fvnzs32irw6t-3{list-style-type:none}ul.lst-kix_fvnzs32irw6t-4{list-style-type:none}ul.lst-kix_fvnzs32irw6t-1{list-style-type:none}ul.lst-kix_fvnzs32irw6t-2{list-style-type:none}ul.lst-kix_fvnzs32irw6t-0{list-style-type:none}ul.lst-kix_26ltftm3v6k8-1{list-style-type:none}.lst-kix_26ltftm3v6k8-2>li:before{content:"\0025a0   "}ul.lst-kix_26ltftm3v6k8-0{list-style-type:none}.lst-kix_26ltftm3v6k8-1>li:before{content:"\0025cb   "}ul.lst-kix_26ltftm3v6k8-3{list-style-type:none}ul.lst-kix_26ltftm3v6k8-2{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-5{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-7{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-4{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-8{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-7{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-6{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-1{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-3{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-0{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-4{list-style-type:none}ul.lst-kix_qhi6vxoyigf9-3{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-5{list-style-type:none}.lst-kix_26ltftm3v6k8-3>li:before{content:"\0025cf   "}ul.lst-kix_qhi6vxoyigf9-2{list-style-type:none}ul.lst-kix_w9h3dmhbegf2-6{list-style-type:none}.lst-kix_26ltftm3v6k8-4>li:before{content:"\0025cb   "}.lst-kix_26ltftm3v6k8-6>li:before{content:"\0025cf   "}ul.lst-kix_qhi6vxoyigf9-8{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_26ltftm3v6k8-5>li:before{content:"\0025a0   "}.lst-kix_26ltftm3v6k8-8>li:before{content:"\0025a0   "}.lst-kix_qhi6vxoyigf9-5>li:before{content:"\0025a0   "}.lst-kix_w9h3dmhbegf2-0>li:before{content:"\0025cf   "}.lst-kix_iaqg1toqrhdi-2>li:before{content:"\0025a0   "}.lst-kix_qhi6vxoyigf9-7>li:before{content:"\0025cb   "}.lst-kix_qhi6vxoyigf9-8>li:before{content:"\0025a0   "}.lst-kix_26ltftm3v6k8-7>li:before{content:"\0025cb   "}.lst-kix_qhi6vxoyigf9-4>li:before{content:"\0025cb   "}.lst-kix_iaqg1toqrhdi-3>li:before{content:"\0025cf   "}.lst-kix_iaqg1toqrhdi-4>li:before{content:"\0025cb   "}.lst-kix_iaqg1toqrhdi-6>li:before{content:"\0025cf   "}.lst-kix_qhi6vxoyigf9-6>li:before{content:"\0025cf   "}.lst-kix_iaqg1toqrhdi-5>li:before{content:"\0025a0   "}ol{margin:0;padding:0}table td,table th{padding:0}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17pt;font-family:"Arial";font-style:normal}.c3{background-color:#ffffff;padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c6{background-color:#ffffff;padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c10{background-color:#ffffff;padding-top:18pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{font-weight:400;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c0{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c14{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c16{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c5{color:inherit;text-decoration:inherit}.c7{padding:0;margin:0}.c4{margin-left:36pt;padding-left:0pt}.c13{height:11pt}.c15{background-color:#ffffff}.c11{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c15 c16 doc-content"><p class="c12"><span class="c1 c15">This page discusses some overall system architectures and their pros and cons.</span></p><p class="c3"><span class="c1">The general question is how do we make sure high priority works gets done with low enough latency while dealing with deadlock and priority inheritance while making the application developer&#39;s life as simple as possible.</span></p><p class="c3"><span class="c1">There are system issues with priority inheritance and deadlock, when there are threads using shared data structures. Locks prevent high priority work from being performed.</span></p><h2 class="c10" id="h.fe9hwtydefid"><span class="c2">General Issues</span></h2><ul class="c7 lst-kix_fvnzs32irw6t-0 start"><li class="c3 c4 li-bullet-0"><span class="c1">Scheduling High Priority Work - If high priority work comes in while lower priority work is comming in, how do we make sure the high priority work gets handled in a bounded period of time?</span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DPriorityInheritance&amp;sa=D&amp;source=editors&amp;ust=1759177667312760&amp;usg=AOvVaw2A1NKDZvG4l3oENKVswaoi">Priority Inheritance</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DDeadLock&amp;sa=D&amp;source=editors&amp;ust=1759177667312902&amp;usg=AOvVaw0Om-1sFs71AZZao7nflzEP">Dead Lock</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DOSLatency&amp;sa=D&amp;source=editors&amp;ust=1759177667313009&amp;usg=AOvVaw2moVJPsg_2_v3moP62S73R">OS Latency</a></span></li><li class="c3 c4 li-bullet-0"><span class="c1">Shared Locks - The problem with threading is shared locks between different applications.</span></li><li class="c3 c4 li-bullet-0"><span class="c1">Ease of Programming Model</span></li><li class="c3 c4 li-bullet-0"><span class="c1">Robustness of Programming Model</span></li><li class="c3 c4 li-bullet-0"><span class="c1">Minimizing Lock Scope</span></li><li class="c3 c4 li-bullet-0"><span class="c1">Flow Control</span></li><li class="c3 c4 li-bullet-0"><span class="c1">Reasonable Use of Memory and Tasking</span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DTimeSlice&amp;sa=D&amp;source=editors&amp;ust=1759177667313475&amp;usg=AOvVaw35QUf6jiJKzkGGkNJ_KnQ_">Time Slice</a></span></li><li class="c3 c4 li-bullet-0"><span class="c1">Starvation</span></li></ul><h3 class="c6" id="h.k14ie1jdzuz7"><span class="c8">Discussion</span></h3><p class="c3"><span>For example, a management station performs an iterator </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGetNext&amp;sa=D&amp;source=editors&amp;ust=1759177667313724&amp;usg=AOvVaw1_PNDUZ1cnWBnvKIH-ipZR">GetNext</a></span><span>&nbsp;request on a table. An object create operation comes in for the same table, which has a higher priority than the </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGetNext&amp;sa=D&amp;source=editors&amp;ust=1759177667313890&amp;usg=AOvVaw2GK5JA1Ug2twKe0nOYhPmd">GetNext</a></span><span>&nbsp;request. The create is blocked om the </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGetNext&amp;sa=D&amp;source=editors&amp;ust=1759177667313998&amp;usg=AOvVaw38i4yRmlEpTT99QqQXTzr0">GetNext</a></span><span class="c1">&nbsp;container lock.</span></p><p class="c3"><span class="c1">As serialization is occuring this lock may be held for a relatively long period of time.</span></p><p class="c3"><span>A solution is for the </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGetNext&amp;sa=D&amp;source=editors&amp;ust=1759177667314234&amp;usg=AOvVaw0Bq5SLu8aGH8BPGq-z1yBg">GetNext</a></span><span class="c1">&nbsp;to give up the lock every time through its loop and reestablish the cursor every time through the loop. Not something you would ever do naturally.</span></p><p class="c3"><span class="c1">Interestingly, this ends up being a form of cooperative multitasking. I don&#39;t see a way not to do this in one form or another.</span></p><p class="c3"><span class="c1">Old apple and windows systems originally used cooperative multitasking when they didn&#39;t have real threads. You may have seen code with yields sprinkled everywhere. The systems usually performed horribly because the scheduling was always unfair.</span></p><p class="c3"><span class="c1">Threads help with latency. The object create can get scheduled immediately, which is important in a real-time system.</span></p><p class="c3"><span class="c1">But when there&#39;s a shared lock anywhere we are back to potentially poor scheduling because the high priority task must wait on the low priority task. This requires anyone who shares the lock to know there is high priority work and never to take more time than the worst case performance needed for the high priority work. Of course, this changes dynamically as code changes and with different load scenarios.</span></p><p class="c3"><span class="c1">So don&#39;t share a lock. That&#39;s ideal. Hopefully your app will allow you this option. Though calls like memory allocation get you into the shared lock business. Thread specific memory pools are a potential way around this.</span></p><p class="c3"><span class="c1">Not sharing locks is harder than it looks because applications have multiple legitimate clients. A container access objects and objects access containers. How can they not conflict? There are non blocking locking algorithms that are very complex. There a copying strategies that can reduce locking, but we don&#39;t have a lot of memory, and any copy must eventually take a lock.</span></p><h2 class="c10" id="h.hxepfsx0n1k4"><span class="c2">On Threading</span></h2><p class="c3"><span>Threads are somewhat of a religious issue. A lot of people </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DWhatIsWrongWithThreads&amp;sa=D&amp;source=editors&amp;ust=1759177667315908&amp;usg=AOvVaw3BmT-3OnYDUPyuIrQU_Dwf">dislike </a></span><span>threads because multithreaded programming is difficult. This is true when it is done incorrectly. In an environment like </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DErlang&amp;sa=D&amp;source=editors&amp;ust=1759177667316086&amp;usg=AOvVaw3ko-xdWVrgvfB69truuJV2">Erlang</a></span><span class="c1">&nbsp;multithreading is safe and efficient. In Java or C++ it can easily be unsafe and inefficient.</span></p><p class="c3"><span class="c1">So why do we use threads at all?</span></p><ul class="c7 lst-kix_w9h3dmhbegf2-0 start"><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DLatency&amp;sa=D&amp;source=editors&amp;ust=1759177667316322&amp;usg=AOvVaw30-2hi3RSXZx9mGPnD9XZy">latency</a></span><span>. In a real-time system some work must be performed with very low latency. In a </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DRunToCompletion&amp;sa=D&amp;source=editors&amp;ust=1759177667316476&amp;usg=AOvVaw3IKdynj-OuzrXAi-VV_WdI">run to completion</a></span><span class="c1">&nbsp;approach latency can not be guaranteed.</span></li><li class="c3 c4 li-bullet-0"><span class="c11">priority</span><span class="c1">. In a real-time system we want more important work to be performed over lower priority work. Threads provide this ability because they can be preempted.</span></li><li class="c3 c4 li-bullet-0"><span class="c11">fairness</span><span class="c1">. Preemption allows multiple threads to make progress on work. One thread doesn&#39;t starve everyone at the same priority.</span></li><li class="c3 c4 li-bullet-0"><span class="c11">policy domain</span><span class="c1">. A thread can be a domain for policies that you may or may not want applied to different applications. Examples are: priority, floating point safety, stack space, thread local storage, blocking, memory allocation.</span></li></ul><p class="c3"><span class="c1">The key to safe thread usage is not using shared data structures protected by locks. It is lock protected shared data structures that cause latency issues, deadlock, and priority inheritance. It is nearly impossible for a human to make a correct system when any thread can access shared state.</span></p><p class="c3"><span class="c1">Threading can also be bad when thread scheduling is slow. On real-time systems threads are usually very efficiently scheduled, so it is not a concern.</span></p><h2 class="c10" id="h.ppyj3sne9d4"><span class="c2">Lock Used Within an Application is OK?</span></h2><p class="c3"><span class="c1">An application that uses multiple threads and has a lock usable just within the application may not, if care is taken, suffer from the same problems as when locks are arbitrarily used from different application threads.</span></p><p class="c3"><span class="c1">A single application can:</span></p><ul class="c7 lst-kix_26ltftm3v6k8-0 start"><li class="c3 c4 li-bullet-0"><span class="c1">guarantee the amount of time spent blocked on the lock</span></li><li class="c3 c4 li-bullet-0"><span class="c1">prevent deadlock because it probably won&#39;t do work in different threads</span></li><li class="c3 c4 li-bullet-0"><span class="c1">prevent priority inheritance</span></li></ul><h2 class="c10" id="h.90qm54z1cd25"><span class="c2">Thread Model</span></h2><p class="c3"><span class="c1">Applications don&#39;t have their own thread, they are always operating out of someone elses thread.</span></p><p class="c3"><span class="c1">Dead lock in this model is impossible to prevent as application complexity increases. You can never be sure what code will access what locks and what threads are involved in these locks. Latency can&#39;t be guaranteed because you don&#39;t know what operations are being performed in you execution path. Priority inheritance becomes a big problem.</span></p><h2 class="c10" id="h.in0r8pvovffh"><span class="c2">Actor Model (1-1)</span></h2><p class="c3"><span>In the </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DActor&amp;sa=D&amp;source=editors&amp;ust=1759177667318579&amp;usg=AOvVaw3Bg7vtJpDEd8In2lYQpCd-">Actor</a></span><span>&nbsp;model all work for an application is done in a single thread context. An application maps to one thread, thus it is </span><span class="c11">1-1</span><span class="c1">.</span></p><p class="c3"><span class="c1">This model eliminates locks which eliminates priority inheritance and deadlock issues. But we still have the latency for high priority work issue.</span></p><p class="c3"><span>In an Actor context we could introduce the idea of cooperation by having a priority associated with each message. If a higher priority message comes in on the queue then a thread variable &quot;</span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGiveUpWork&amp;sa=D&amp;source=editors&amp;ust=1759177667319107&amp;usg=AOvVaw1XKdYrjuV0uMfrDqepaMB5">GiveUpWork</a></span><span class="c1">&quot; is set. Code in a sensitive a place would check this flag a particular points in its code and stop what it is doing so the higher priority work can be scheduled.</span></p><p class="c3"><span>The </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGetNext&amp;sa=D&amp;source=editors&amp;ust=1759177667319348&amp;usg=AOvVaw2-oPHDB1wTQxID-xjZJI08">GetNext</a></span><span>, for example, at the top of the loop would check the </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DGiveUpWork&amp;sa=D&amp;source=editors&amp;ust=1759177667319472&amp;usg=AOvVaw3i0WvAMLgL5Yy46I_svjA1">GiveUpWork</a></span><span class="c1">&nbsp;flag and stop what it is doing. In this case the client is guaranteed a batch size so stopping at any point is ok. We could also cause the request to be put back on the queue so it could be tried later. Notice we are potentially starving lower priority work.</span></p><p class="c3"><span class="c1">An implication is to change the actor&#39;s priority accordingly with the highest priority work in its queue.</span></p><p class="c3"><span class="c1">This is another form cooperative multitasking. It has the advantage of eliminating deadlock and priority inheritance. But it is kind of ugly.</span></p><h2 class="c10" id="h.4lfk41k7gduf"><span class="c2">Actor With Thread Pool (1-N)</span></h2><p class="c3"><span class="c1">Like the Actor model but a thread pool is used instead of just one thread. Only shared locks under complete control of the application are required.</span></p><h2 class="c10" id="h.sowbscgf6mp5"><span class="c2">Actor Arbitrary Thread Model</span></h2><p class="c3"><span class="c1">A hybrid is an application may have an Actor so it has a thread but other threads access the actor so shared locks are necessary to protect data. It&#39;s easy to have a lot of this because not everyone is disciplined about using only message passing between actors.</span></p><p class="c3"><span class="c1">This is some ways the worse of all possible worlds. The Actor model is supposed to be a safe programming model, but instead it degenerates into a thread and lock nightmare. Selecting a language that implements a pure model will prevent this sort of hybrid.</span></p><h2 class="c10" id="h.34ccxonvnrm6"><span class="c2">Multiple Actor Model</span></h2><p class="c3"><span class="c1">Work can be routed to multiple actors. Low priority work can go to one actor. High priority work can go to another. Parallelism is added by adding more actors. Using a worker pool is another similar approach.</span></p><p class="c3"><span class="c1">A lock is still necessary because the actors share state.</span></p><p class="c3"><span class="c1">The advantage is the lock is kept inside one application so the application is totally responsible for locking behaviour. Another subsystem couldn&#39;t spike your times.</span></p><p class="c3"><span class="c1">The disadvantage is this architecture is more complex for applications to create. Message order issues also arise if parallel work is spread across multiple actors.</span></p><h2 class="c10" id="h.llt2kovev6j"><span class="c2">Event Queue Model</span></h2><p class="c3"><span class="c1">In the event queue model work is represented by events. Events are queued up to one thread or sometimes a few threads of different priorities. Applications don&#39;t have their own thread. All application work is queued up in event threads. Applications are usually asynchronous.</span></p><p class="c3"><span class="c1">Obviously with multiple threads deadlock and locking issues still apply. One thread is safer but other issues arise. The single thread issues are priority and latency. The same sort of issues that are already addressed in thread scheduling system, which is why i&#39;ve never really like the model because you have to write your own scheduler.</span></p><p class="c3"><span class="c1">But, you still need cooperative multitasking, which makes it largely the same as the actor model.</span></p><p class="c3"><span>Event model is attractive where most of the work is of approximately equal and small size. This model has been used very well in state machine oriented computation (</span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DCSP&amp;sa=D&amp;source=editors&amp;ust=1759177667322359&amp;usg=AOvVaw1V44vKT3BxQisqd819owVg">communicating finite state machines </a></span><span class="c1">where state transitions require deterministic and small time. Breaking down your system to make it suitable for this model is big job. Paybacks are reduced complexity of implementation. Message or event priorities can be used in this model. This model is usually based on run to completion kind of scheduling.</span></p><p class="c3"><span class="c1">If latency is an important issue the event model can&#39;t be used, at least everywhere as you&#39;ll never be able to guarantee latency. Attempts to guarantee latency basically require writing another level of scheduling.</span></p><h2 class="c10" id="h.5o9culy0ogmn"><span class="c2">Actor + Parallel State Machine Model</span></h2><p class="c3"><span class="c1">If synchronous logic is used then an actor can not process high priority messages when a low priority message is being processed.</span></p><p class="c3"><span class="c1">One alternative is to use a state machine model in the processing of the request. The message is sent to the other actor and the reply is expected on a specific message queue. Now the actor begins the processing of the high priority message. Next time it picks up a message it can look for the reply message and resume processing of the low priority message. Having a separate message queue simply makes looking for the reply rather trivial.</span></p><p class="c3"><span class="c1">In short, having multiple message queues for different priority messages combined with state machine driven message processing when required can potentially give, in many situations, low latency processing of high priority messages.</span></p><p class="c3"><span class="c1">For example, msg1 comes at high priority, then msg2 comes in at medium priority, and then comes msg3 at the low priory. The assignment of these priorities to different requests is part of application protocol design. The heuristics used by an application as follows. Process msg1 first. If more than 90 ms is spent processing msg1 and msg2 is starving, process one msg2 for 10 ms and then go back to msg1 processing.</span></p><p class="c3"><span class="c1">If a msg3 is pending and it has not been processed for the last 1 minute, process msg3. Note that in this example each message is processed to completion. The heuristic kicks in to avoid starvation when large number of requests comes in.</span></p><p class="c3"><span class="c1">The state machine is parallel in terms of the number of requests it can take. For each request processed you create a context for the request and the context is driven by the state machine. You might, for example, get a flood of msg1s. For each msg1 being processed, there will be a context block for storing an id (for context identification purpose), current state, and various associated data. As hundreds of msg1s are processed, hundreds of these contexts are created. One of the state these contexts go through is communication to another node. There is a timer associated with each context in case reply times out. As ACK comes in or the timer fires, the associated context makes its state transition.</span></p><p class="c3"><span class="c1">Many applications can be implemented in a straight forward fashion in this model to achieve high throughput and low latency for high priority work.</span></p><p class="c3"><span class="c1">Starvation, deadlock, dependencies are application protocol layer issues. One can build tools to describe the dependencies with a high level descriptive syntax of some sort and have the underlying infrastructure implement them.</span></p><h2 class="c10" id="h.cn2tp9a7c7f"><span class="c2">Dataflow Model</span></h2><p class="c3"><span>A technique used in </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.mozart-oz.org/documentation/tutorial/&amp;sa=D&amp;source=editors&amp;ust=1759177667325651&amp;usg=AOvVaw3MxpmA_iolrOuhWN_NTXgb">functional languages </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c1">. It allows users to dynamically create any number of sequential threads. The threads are dataflow threads in the sense that a thread executing an operation will suspend until all operands needed have a well-defined value.</span></p><h2 class="c10" id="h.zbc2zlbcchp3"><span class="c2">Erlang Model</span></h2><p class="c3"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.guug.de/veranstaltungen/ffg2003/papers/ffg2003-armstrong.pdf&amp;sa=D&amp;source=editors&amp;ust=1759177667326311&amp;usg=AOvVaw2HOFcRmdCiF5s0Rb7adCcM">http://www.guug.de/veranstaltungen/ffg2003/papers/ffg2003-armstrong.pdf</a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c1">.</span></p><p class="c3"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DErlang&amp;sa=D&amp;source=editors&amp;ust=1759177667326432&amp;usg=AOvVaw2Nj_jjz08yBl5ZD7cH5Qyk">Erlang</a></span><span class="c1">&nbsp;has a process-based model of concurrency with asynchronous message passing. The processes are light-weight, i.e require little memory; creating and deleting processes and message passing require little computational effort.</span></p><p class="c3"><span class="c1">No shared memory, all interaction between processes is by asynchronous message passing. The distribution is location transparent. The program does not have to consider whether the recipient of a message is a local process or located on a remote Erlang virtual machine.</span></p><h2 class="c10" id="h.4ss5sz41457b"><span class="c2">SEDA Model</span></h2><p class="c3"><span class="c1">SEDA is an acronym for staged event-driven architecture, and decomposes a complex, event-driven application into a set of stages connected by queues. Each queue has a thread pool to execute work from the queue.</span></p><p class="c3"><span class="c1">This design avoids the high overhead associated with thread-based concurrency models, and decouples event and thread scheduling from application logic. By performing admission control on each event queue, the service can be well-conditioned to load, preventing resources from being overcommitted when demand exceeds service capacity. SEDA employs dynamic control to automatically tune runtime parameters (such as the scheduling parameters of each stage), as well as to manage load, for example, by performing adaptive load shedding. Decomposing services into a set of stages also enables modularity and code reuse, as well as the development of debugging tools for complex event-driven applications.</span></p><h2 class="c10" id="h.rl7xgr1jju27"><span class="c2">Multiple Application Thread Pool Model (M - N)</span></h2><p class="c3"><span>In this model multiple applications are multiplexed over the the same thread pool. The pool may have only one thread. This could be considered a container for the parallel state machine or event model. See </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DAppBackplane&amp;sa=D&amp;source=editors&amp;ust=1759177667328386&amp;usg=AOvVaw0e0FM7E7Lk7zmE7ZCwqHaZ">App Backplane</a></span><span class="c1">&nbsp;for an exploration of this &quot;best of all worlds&quot; approach.</span></p><h2 class="c10" id="h.90ie73k8u02t"><span class="c2">Where is the state machine?</span></h2><p class="c3"><span>Every application can be described by an explicit or implicit </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DStateMachine&amp;sa=D&amp;source=editors&amp;ust=1759177667328710&amp;usg=AOvVaw29KX2qfWsoOW7KMVVyRLUY">state machine</a></span><span class="c1">. In the actor model the state machine is often implicit on the stack and in the state of the actor. Clearly an actor can use a state machine, but it is often easier for developers to not use a formal state machine.</span></p><p class="c3"><span class="c1">In the event and parallel state machine models state machines are usually made explicit because responses are asynchronous which means the response needs to be matched up with the original request. A state machine is a natural way to do this.</span></p><p class="c3"><span class="c1">Applications built around state machines tend to be more robust.</span></p><h2 class="c10" id="h.3e3q5752zn9t"><span class="c2">Remote Queue Case Study</span></h2><p class="c3"><span class="c1">The Remote Queue is part of Data Grid library and supports peer-to-peer communication channels.</span></p><p class="c3"><span class="c1">A Remote Queue supports these operations:</span></p><ul class="c7 lst-kix_iaqg1toqrhdi-0 start"><li class="c3 c4 li-bullet-0"><span class="c1">register</span></li><li class="c3 c4 li-bullet-0"><span class="c1">signal timer</span></li><li class="c3 c4 li-bullet-0"><span class="c1">register / get next timer</span></li><li class="c3 c4 li-bullet-0"><span class="c1">get next operation</span></li><li class="c3 c4 li-bullet-0"><span class="c1">get next batch from a peer</span></li><li class="c3 c4 li-bullet-0"><span class="c1">deregister</span></li><li class="c3 c4 li-bullet-0"><span class="c1">available</span></li><li class="c3 c4 li-bullet-0"><span class="c1">signal</span></li><li class="c3 c4 li-bullet-0"><span class="c1">get status</span></li><li class="c3 c4 li-bullet-0"><span class="c1">resolve other poller name space</span></li><li class="c3 c4 li-bullet-0"><span class="c1">add data source</span></li></ul><p class="c3"><span class="c1">If a Remote Queue was an actor then if an application on a node needs to talk to 30 other nodes then there are 30 threads created. If want to use more peer-to-peer channels then the number of threads would increase proportionately.</span></p><p class="c3"><span class="c1">Let&#39;s say there about 200 potentially parallel operations with 30 remote queues.</span></p><h3 class="c6" id="h.qwunpoha51ha"><span class="c8">1-1 Threading</span></h3><p class="c3"><span class="c1">The advantage of the actor per queue model is that all queues are completely independent and the actor is the state machine for operations. Operations for one queue won&#39;t block another queue. Queues can have different priorities.</span></p><p class="c3"><span>We&#39;ll have 30 simultaneous requests which make create </span><span class="c14">flow control</span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Edit.jsp?page%3DFlowControl&amp;sa=D&amp;source=editors&amp;ust=1759177667330873&amp;usg=AOvVaw01vWHOmIhP5QLbSqAUXEDA">?</a></span><span class="c1">&nbsp;problems, especially as the number of threads is increased. For example, we could have 30 simultaneous registration requests. That uses a chunk of memory, but imagine 200 simultaneous messages would use a lot of memory.</span></p><h3 class="c6" id="h.zer24wpp8snb"><span class="c8">1-N Threading</span></h3><p class="c3"><span class="c1">Consider an architecture where all 30 queues multiplex over one actor. No shared locks. Smallest number of threads.</span></p><p class="c3"><span class="c1">Part of the work is to dispatch data to applications where upon the applications will process the data. If this is done then the queue is blocked on applications, which means it could take an arbitrary period of time for the application to complete its work. This means all the other queues aren&#39;t be serviced.</span></p><p class="c3"><span class="c1">We don&#39;t have the ability to gurantee latency or use priority. Other queues are being starved.</span></p><p class="c3"><span class="c1">We could say to each application, &quot;be really fast,&quot; but the won&#39;t work very well.</span></p><h3 class="c6" id="h.bo7y68vko7jn"><span class="c8">M-N Threading</span></h3><p class="c3"><span class="c1">We can have multiple queues assigned to multiple actors. This reduces the blocking factor because each pool of queues will their own thread.</span></p><p class="c3"><span class="c1">Introduces shared locks. Has the same problems has the 1-N solution, though it may be less severe. We are not starving as many queues.</span></p><h3 class="c6" id="h.3uddoempa3j5"><span class="c8">Parallel State Machine Model</span></h3><p class="c3"><span class="c1">We could have each register command be a state machine that sent a register request and wait for an async reply. We could make all 200 operations parallel, which is quite a lot. The remote queue would have to limit the amount of simultaneous work somehow.</span></p><p class="c3"><span class="c1">Application processing of polled data is in the queue thread so this would need to be made async as well.</span></p><p class="c3"><span class="c1">The issue with this approach is always how. The actor/synchronous style is easy to explain and do.</span></p><p class="c3"><span>The </span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DAppBackplane&amp;sa=D&amp;source=editors&amp;ust=1759177667332854&amp;usg=AOvVaw1XeEIoCellNMEA3fYDlzSh">App Backplane</a></span><span class="c1">&nbsp;tries to make this style doable at the application level while handling latency, fairness, dead lock, etc.</span></p><h2 class="c10" id="h.43upo7dmfenc"><span class="c2">References</span></h2><ul class="c7 lst-kix_qhi6vxoyigf9-0 start"><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DWhatIsWrongWithThreads&amp;sa=D&amp;source=editors&amp;ust=1759177667333128&amp;usg=AOvVaw1GTXSWM2e93sX2X46I1omt">What Is Wrong With Threads</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DHandlingInfiniteWorkLoads&amp;sa=D&amp;source=editors&amp;ust=1759177667333274&amp;usg=AOvVaw0YYLwxj6pR9nKJpN-ucDRc">Handling Infinite Work Loads</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DScalabilityProblems&amp;sa=D&amp;source=editors&amp;ust=1759177667333414&amp;usg=AOvVaw1V6VShmgu3OGHGIYeHOnLs">Scalability Problems</a></span><span>/</span><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DScalabilitySolutions&amp;sa=D&amp;source=editors&amp;ust=1759177667333519&amp;usg=AOvVaw1XokmHmrlPb8UfR_kjfXVQ">Scalability Solutions</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DAppBackplane&amp;sa=D&amp;source=editors&amp;ust=1759177667333655&amp;usg=AOvVaw0XVfcL5ZE7r8ATO_u9903R">App Backplane</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DSeda&amp;sa=D&amp;source=editors&amp;ust=1759177667333768&amp;usg=AOvVaw2_M7dWCl0UjZQE0DAjoA3q">seda</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DErlang&amp;sa=D&amp;source=editors&amp;ust=1759177667333883&amp;usg=AOvVaw0x2ktM1OA1H7iXwqFoyO3T">Erlang</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.cs.berkeley.edu/~jcondit/threads-hotos-2003.pdf&amp;sa=D&amp;source=editors&amp;ust=1759177667334028&amp;usg=AOvVaw37ryinAViqptaPeG1CGVpQ">Why Events Are A Bad Idea </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://deuce.doc.wustl.edu/doc/pspdfs/lf.pdf&amp;sa=D&amp;source=editors&amp;ust=1759177667334164&amp;usg=AOvVaw1K93gq0RIeR6EKofDF5O9r">Leader/Followers </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.cs.wustl.edu/~schmidt/ACE.html&amp;sa=D&amp;source=editors&amp;ust=1759177667334295&amp;usg=AOvVaw1OYHQ-Exd56Xv9aKoV85FR">Adaptive Communication Environment </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://research.sun.com/techrep/1994/smli_tr-94-29.pdf&amp;sa=D&amp;source=editors&amp;ust=1759177667334428&amp;usg=AOvVaw3LtYkY6j908zB1UG4OOMtX">Notes on Distributed Computing </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.acisinc.com/&amp;sa=D&amp;source=editors&amp;ust=1759177667334546&amp;usg=AOvVaw2KDDMR0uUSN0ZaMJxZJQly">Cycle Free Scheduling </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://www.possibility.com/epowiki/Wiki.jsp?page%3DJetPropulsionArchitecture&amp;sa=D&amp;source=editors&amp;ust=1759177667334689&amp;usg=AOvVaw3mQLmbryh70c20JnjhiXaS">Jet Propulsion Architecture</a></span></li><li class="c3 c4 li-bullet-0"><span class="c0"><a class="c5" href="https://www.google.com/url?q=https://web.archive.org/web/20071023023445/http://ddj.com/dept/64bit/200001985&amp;sa=D&amp;source=editors&amp;ust=1759177667334816&amp;usg=AOvVaw2eOeUjL92FGZGuBOfnhInM">The Pillars of Concurrency </a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 6.00px; height: 6.00px;"><img alt="" src="images/image1.png" style="width: 6.00px; height: 6.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c1">&nbsp;- Building a consistent mental model for reasoning about concurrency</span></li></ul><p class="c12 c13"><span class="c1"></span></p><p class="c12 c13"><span class="c1"></span></p></body></html>